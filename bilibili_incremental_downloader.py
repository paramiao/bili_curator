#!/usr/bin/env python3
"""
Bç«™åˆé›†å¢é‡ä¸‹è½½å™¨
åŸºäºå·²æœ‰è§†é¢‘IDåˆ—è¡¨è¿›è¡Œå¢é‡æ›´æ–°
"""

import os
import sys
import json
import subprocess
import re
import time
import random
import argparse
from pathlib import Path
import logging

class BilibiliIncrementalDownloader:
    def __init__(self, output_dir, max_videos=None, quality='best', cookies=None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.max_videos = max_videos
        self.quality = quality
        self.cookies = cookies
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # æ ¼å¼å›é€€åˆ—è¡¨
        self.format_fallbacks = [
            'best[height<=1080]',
            'best[height<=720]', 
            'best[height<=480]',
            'best[ext=mp4]',
            'best[ext=flv]',
            'bestvideo+bestaudio/best',
            'best',
            'worst'
        ]
        
        # å¤„ç†Cookie
        self.cookie_file = None
        if self.cookies:
            self.setup_cookies()
        
        # åŠ è½½å·²ä¸‹è½½çš„è§†é¢‘ID
        self.downloaded_ids = self.load_downloaded_ids()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_file = self.output_dir / 'incremental_download.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def setup_cookies(self):
        """è®¾ç½®Cookieæ–‡ä»¶"""
        try:
            self.logger.info(f"æ­£åœ¨è®¾ç½®Cookie...")
            
            if self.cookies.startswith('/') and self.cookies.endswith('.txt'):
                self.cookie_file = Path(self.cookies)
                if self.cookie_file.exists():
                    self.logger.info(f"âœ“ ä½¿ç”¨ç°æœ‰Cookieæ–‡ä»¶: {self.cookie_file}")
                    return
                else:
                    self.cookie_file.parent.mkdir(parents=True, exist_ok=True)
            else:
                self.cookie_file = self.output_dir / 'cookies.txt'
            
            # è§£æCookieå†…å®¹
            cookie_content = "# Netscape HTTP Cookie File\n"
            
            if self.cookies.startswith('SESSDATA='):
                sessdata_value = self.cookies.split('=', 1)[1]
                cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\tSESSDATA\t{sessdata_value}\n"
            elif ';' in self.cookies:
                for cookie in self.cookies.split(';'):
                    cookie = cookie.strip()
                    if '=' in cookie:
                        name, value = cookie.split('=', 1)
                        name = name.strip()
                        value = value.strip()
                        cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\t{name}\t{value}\n"
            else:
                cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\tSESSDATA\t{self.cookies}\n"
            
            with open(self.cookie_file, 'w', encoding='utf-8') as f:
                f.write(cookie_content)
            
            self.logger.info(f"âœ“ Cookieæ–‡ä»¶å·²åˆ›å»º: {self.cookie_file}")
            
        except Exception as e:
            self.logger.error(f"âœ— è®¾ç½®Cookieå¤±è´¥: {e}")
            self.cookie_file = None
    
    def load_downloaded_ids(self):
        """åŠ è½½å·²ä¸‹è½½çš„è§†é¢‘ID"""
        id_file = self.output_dir / 'downloaded_video_ids.txt'
        downloaded_ids = set()
        
        if id_file.exists():
            try:
                with open(id_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        video_id = line.strip()
                        if video_id:
                            downloaded_ids.add(video_id)
                
                self.logger.info(f"âœ“ åŠ è½½å·²ä¸‹è½½è§†é¢‘ID: {len(downloaded_ids)}ä¸ª")
                
                # æ˜¾ç¤ºæœ€è¿‘å‡ ä¸ªID
                if downloaded_ids:
                    recent_ids = list(downloaded_ids)[-5:]
                    self.logger.info(f"  æœ€è¿‘ID: {', '.join(recent_ids)}")
                
            except Exception as e:
                self.logger.warning(f"åŠ è½½è§†é¢‘IDæ–‡ä»¶å¤±è´¥: {e}")
        else:
            self.logger.info("æœªæ‰¾åˆ°å·²ä¸‹è½½è§†é¢‘IDæ–‡ä»¶ï¼Œå°†ä¸‹è½½æ‰€æœ‰è§†é¢‘")
        
        return downloaded_ids
    
    def get_yt_dlp_base_args(self):
        """è·å–yt-dlpåŸºç¡€å‚æ•°"""
        args = [
            'yt-dlp',
            '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            '--sleep-interval', '3',
            '--max-sleep-interval', '8',
            '--retries', '5',
            '--fragment-retries', '5',
            '--retry-sleep', '3',
            '--ignore-errors',
            '--no-warnings',
        ]
        
        if self.cookie_file and self.cookie_file.exists():
            args.extend(['--cookies', str(self.cookie_file)])
            self.logger.info(f"âœ“ ä½¿ç”¨Cookieæ–‡ä»¶: {self.cookie_file}")
        
        return args
    
    def get_collection_videos(self, collection_url):
        """è·å–åˆé›†ä¸­çš„æ‰€æœ‰è§†é¢‘ä¿¡æ¯"""
        self.logger.info("è·å–åˆé›†è§†é¢‘åˆ—è¡¨...")
        
        cmd = self.get_yt_dlp_base_args() + [
            '--dump-json',
            '--no-download',
            '--flat-playlist',
            collection_url
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode != 0:
                self.logger.error(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {result.stderr}")
                return []
            
            videos = []
            lines = result.stdout.strip().split('\n')
            
            for line in lines:
                if line.strip():
                    try:
                        video_info = json.loads(line)
                        video_id = video_info.get('id', '')
                        title = video_info.get('title', '')
                        url = video_info.get('url', '')
                        
                        if video_id and title:
                            videos.append({
                                'id': video_id,
                                'title': title,
                                'url': url,
                                'info': video_info
                            })
                    except json.JSONDecodeError:
                        continue
            
            self.logger.info(f"âœ“ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
            return videos
            
        except Exception as e:
            self.logger.error(f"è·å–è§†é¢‘åˆ—è¡¨å‡ºé”™: {e}")
            return []
    
    def filter_new_videos(self, all_videos):
        """è¿‡æ»¤å‡ºæ–°è§†é¢‘"""
        new_videos = []
        
        for video in all_videos:
            video_id = video['id']
            if video_id not in self.downloaded_ids:
                new_videos.append(video)
            else:
                self.logger.info(f"è·³è¿‡å·²ä¸‹è½½: {video_id} - {video['title']}")
        
        self.logger.info(f"âœ“ å‘ç° {len(new_videos)} ä¸ªæ–°è§†é¢‘éœ€è¦ä¸‹è½½")
        return new_videos
    
    def download_incremental(self, collection_url, collection_name=None):
        """å¢é‡ä¸‹è½½åˆé›†"""
        self.logger.info(f"å¼€å§‹å¢é‡ä¸‹è½½åˆé›†")
        self.logger.info(f"URL: {collection_url}")
        
        # è·å–æ‰€æœ‰è§†é¢‘
        all_videos = self.get_collection_videos(collection_url)
        if not all_videos:
            self.logger.error("æ— æ³•è·å–è§†é¢‘åˆ—è¡¨")
            return False
        
        # è¿‡æ»¤æ–°è§†é¢‘
        new_videos = self.filter_new_videos(all_videos)
        
        if not new_videos:
            self.logger.info("âœ“ æ²¡æœ‰æ–°è§†é¢‘éœ€è¦ä¸‹è½½")
            return True
        
        # é™åˆ¶ä¸‹è½½æ•°é‡
        if self.max_videos and len(new_videos) > self.max_videos:
            new_videos = new_videos[:self.max_videos]
            self.logger.info(f"é™åˆ¶ä¸‹è½½æ•°é‡: {len(new_videos)}")
        
        # è·å–æˆ–åˆ›å»ºåˆé›†ç›®å½•
        if not collection_name:
            collection_name = self.get_collection_name(collection_url)
        
        collection_dir = self.output_dir / collection_name
        collection_dir.mkdir(exist_ok=True)
        
        # ä¸‹è½½æ–°è§†é¢‘
        success_count = 0
        new_downloaded_ids = []
        
        for i, video in enumerate(new_videos, 1):
            self.logger.info(f"\nä¸‹è½½è¿›åº¦: {i}/{len(new_videos)}")
            self.logger.info(f"è§†é¢‘: {video['id']} - {video['title']}")
            
            if self.download_single_video(video, collection_dir, i):
                success_count += 1
                new_downloaded_ids.append(video['id'])
            
            # éšæœºå»¶æ—¶
            if i < len(new_videos):
                delay = random.uniform(5, 10)
                self.logger.info(f"ç­‰å¾… {delay:.1f} ç§’...")
                time.sleep(delay)
        
        # æ›´æ–°å·²ä¸‹è½½IDåˆ—è¡¨
        if new_downloaded_ids:
            self.update_downloaded_ids(new_downloaded_ids)
        
        self.logger.info(f"\nâœ… å¢é‡ä¸‹è½½å®Œæˆ: {success_count}/{len(new_videos)} ä¸ªè§†é¢‘")
        
        # å¦‚æœæœ‰æ–°ä¸‹è½½çš„è§†é¢‘ï¼Œè¿è¡Œç›®å½•ç®¡ç†å™¨
        if success_count > 0:
            self.logger.info("è¿è¡Œç›®å½•ç®¡ç†å™¨...")
            self.run_directory_manager(collection_dir)
        
        return success_count > 0
    
    def download_single_video(self, video, collection_dir, index):
        """ä¸‹è½½å•ä¸ªè§†é¢‘"""
        video_id = video['id']
        video_url = f"https://www.bilibili.com/video/{video_id}"
        
        # ä½¿ç”¨æ ¼å¼å›é€€
        for format_selector in self.format_fallbacks:
            self.logger.info(f"  å°è¯•æ ¼å¼: {format_selector}")
            
            if self.download_with_format(video_url, collection_dir, format_selector, index, video_id):
                self.logger.info(f"  âœ“ ä¸‹è½½æˆåŠŸ: {format_selector}")
                return True
            else:
                self.logger.warning(f"  æ ¼å¼å¤±è´¥: {format_selector}")
        
        self.logger.error(f"  âœ— æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥")
        return False
    
    def download_with_format(self, video_url, collection_dir, format_selector, index, video_id):
        """ä½¿ç”¨æŒ‡å®šæ ¼å¼ä¸‹è½½"""
        try:
            cmd = self.get_yt_dlp_base_args() + [
                '--format', format_selector,
                '--output', f'{index:02d}_{video_id}.%(ext)s',
                '--write-info-json',
                '--write-thumbnail',
                '--convert-thumbnails', 'jpg',
                video_url
            ]
            
            result = subprocess.run(
                cmd, 
                cwd=collection_dir, 
                capture_output=True, 
                text=True,
                timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode == 0:
                return True
            else:
                if "Requested format is not available" in result.stderr:
                    return False  # æ ¼å¼ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                else:
                    self.logger.warning(f"    ä¸‹è½½å¤±è´¥: {result.stderr}")
                    return False
                
        except subprocess.TimeoutExpired:
            self.logger.warning(f"    ä¸‹è½½è¶…æ—¶")
            return False
        except Exception as e:
            self.logger.warning(f"    ä¸‹è½½å‡ºé”™: {e}")
            return False
    
    def get_collection_name(self, collection_url):
        """è·å–åˆé›†åç§°"""
        cmd = self.get_yt_dlp_base_args() + [
            '--dump-json',
            '--no-download',
            '--flat-playlist',
            '--playlist-items', '1',
            collection_url
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if line.strip():
                        try:
                            info = json.loads(line)
                            collection_name = (
                                info.get('playlist_title') or 
                                info.get('uploader', 'Unknown') + '_Collection'
                            )
                            if collection_name and collection_name != 'NA':
                                return self.sanitize_filename(collection_name)
                        except json.JSONDecodeError:
                            continue
            
            return "Unknown_Collection"
            
        except Exception as e:
            self.logger.warning(f"è·å–åˆé›†åç§°å¤±è´¥: {e}")
            return "Unknown_Collection"
    
    def update_downloaded_ids(self, new_ids):
        """æ›´æ–°å·²ä¸‹è½½IDåˆ—è¡¨"""
        id_file = self.output_dir / 'downloaded_video_ids.txt'
        
        # æ·»åŠ æ–°IDåˆ°é›†åˆ
        self.downloaded_ids.update(new_ids)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(id_file, 'w', encoding='utf-8') as f:
                for video_id in sorted(self.downloaded_ids):
                    f.write(f"{video_id}\n")
            
            self.logger.info(f"âœ“ æ›´æ–°è§†é¢‘IDåˆ—è¡¨: æ–°å¢ {len(new_ids)} ä¸ªï¼Œæ€»è®¡ {len(self.downloaded_ids)} ä¸ª")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°è§†é¢‘IDåˆ—è¡¨å¤±è´¥: {e}")
    
    def run_directory_manager(self, collection_dir):
        """è¿è¡Œç›®å½•ç®¡ç†å™¨"""
        try:
            # å¯¼å…¥ç›®å½•ç®¡ç†å™¨
            sys.path.append(str(Path(__file__).parent))
            from bilibili_directory_manager import BilibiliDirectoryManager
            
            manager = BilibiliDirectoryManager(collection_dir)
            manager.process_directory()
            
        except Exception as e:
            self.logger.warning(f"è¿è¡Œç›®å½•ç®¡ç†å™¨å¤±è´¥: {e}")
            self.logger.info("è¯·æ‰‹åŠ¨è¿è¡Œç›®å½•ç®¡ç†å™¨:")
            self.logger.info(f"python bilibili_directory_manager.py \"{collection_dir}\"")
    
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        if not filename or filename.strip() == '':
            return 'untitled'
        
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'[\r\n\t]', ' ', filename)
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = filename.strip('. ')
        filename = re.sub(r'[ã€ã€‘\[\]()ï¼ˆï¼‰]', '', filename)
        filename = re.sub(r'[!ï¼@#$%^&*+={}|;:,.<>?~`]', '_', filename)
        
        if len(filename) > 80:
            filename = filename[:80].rsplit(' ', 1)[0]
        
        return filename or 'untitled'
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self.cookie_file and self.cookie_file.name == 'cookies.txt':
            try:
                if self.cookie_file.exists():
                    self.cookie_file.unlink()
            except:
                pass

def main():
    parser = argparse.ArgumentParser(
        description='Bç«™åˆé›†å¢é‡ä¸‹è½½å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
åŠŸèƒ½:
- åŸºäºå·²æœ‰è§†é¢‘IDåˆ—è¡¨è¿›è¡Œå¢é‡æ›´æ–°
- åªä¸‹è½½æ–°è§†é¢‘ï¼Œè·³è¿‡å·²ä¸‹è½½çš„è§†é¢‘
- è‡ªåŠ¨æ›´æ–°è§†é¢‘IDåˆ—è¡¨
- ä¸‹è½½å®Œæˆåè‡ªåŠ¨è¿è¡Œç›®å½•ç®¡ç†å™¨

ç¤ºä¾‹:
  %(prog)s "åˆé›†URL" "./downloads" --cookies "SESSDATA=xxx" --max-videos 5
        """
    )
    
    parser.add_argument('url', help='Bç«™åˆé›†URL')
    parser.add_argument('output', help='è¾“å‡ºæ ¹ç›®å½•')
    parser.add_argument('--name', help='è‡ªå®šä¹‰åˆé›†åç§°')
    parser.add_argument('--max-videos', type=int, help='æœ€å¤§ä¸‹è½½æ–°è§†é¢‘æ•°é‡')
    parser.add_argument('--quality', default='best', help='è§†é¢‘è´¨é‡')
    parser.add_argument('--cookies', help='Cookieå­—ç¬¦ä¸²æˆ–Cookieæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    if 'bilibili.com' not in args.url or 'lists' not in args.url:
        print("é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„Bç«™åˆé›†URL")
        sys.exit(1)
    
    downloader = BilibiliIncrementalDownloader(
        output_dir=args.output,
        max_videos=args.max_videos,
        quality=args.quality,
        cookies=args.cookies
    )
    
    if args.verbose:
        logging.getLogger().setLevel(logging.INFO)
    
    print(f"ğŸš€ Bç«™åˆé›†å¢é‡ä¸‹è½½å™¨")
    print(f"  è¾“å‡ºç›®å½•: {args.output}")
    print(f"  æœ€å¤§æ–°è§†é¢‘æ•°: {args.max_videos or 'æ— é™åˆ¶'}")
    print(f"  è§†é¢‘è´¨é‡: {args.quality}")
    print(f"  Cookie: {'âœ“' if args.cookies else 'âœ—'}")
    print(f"  åŠŸèƒ½: å¢é‡æ›´æ–° + è‡ªåŠ¨ç®¡ç†")
    print()
    
    try:
        success = downloader.download_incremental(args.url, args.name)
        if success:
            print(f"\nâœ… å¢é‡ä¸‹è½½å®Œæˆ!")
        else:
            print(f"\nâŒ å¢é‡ä¸‹è½½å¤±è´¥!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        sys.exit(1)
    finally:
        downloader.cleanup()

if __name__ == '__main__':
    main()

