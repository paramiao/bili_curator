#!/usr/bin/env python3
"""
Bç«™åˆé›†ä¸‹è½½å™¨ - åŸºäºæˆåŠŸç‰ˆæœ¬ï¼Œä¸“é—¨ä¿®å¤é‡å‘½åé—®é¢˜
å›åˆ°æœ€åˆå¯ä»¥ä¸‹è½½æˆåŠŸçš„é€»è¾‘ï¼Œåªä¿®å¤æ–‡ä»¶åé—®é¢˜
"""

import os
import sys
import json
import subprocess
import re
import time
import random
import argparse
from pathlib import Path
import logging

class BilibiliWorkingDownloader:
    def __init__(self, output_dir, max_videos=None, quality='best', cookies=None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.max_videos = max_videos
        self.quality = quality
        self.cookies = cookies
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # æ ¼å¼å›é€€åˆ—è¡¨ï¼ˆåŸºäºä¹‹å‰æˆåŠŸçš„ç‰ˆæœ¬ï¼‰
        self.format_fallbacks = [
            'best[height<=1080]',
            'best[height<=720]', 
            'best[height<=480]',
            'best[ext=mp4]',
            'best[ext=flv]',
            'bestvideo+bestaudio/best',
            'best',
            'worst'
        ]
        
        # å¤„ç†Cookie
        self.cookie_file = None
        if self.cookies:
            self.setup_cookies()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_file = self.output_dir / 'download.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def setup_cookies(self):
        """è®¾ç½®Cookieæ–‡ä»¶"""
        try:
            self.logger.info(f"æ­£åœ¨è®¾ç½®Cookie...")
            
            if self.cookies.startswith('/') and self.cookies.endswith('.txt'):
                self.cookie_file = Path(self.cookies)
                if self.cookie_file.exists():
                    self.logger.info(f"âœ“ ä½¿ç”¨ç°æœ‰Cookieæ–‡ä»¶: {self.cookie_file}")
                    return
                else:
                    self.cookie_file.parent.mkdir(parents=True, exist_ok=True)
            else:
                self.cookie_file = self.output_dir / 'cookies.txt'
            
            # è§£æCookieå†…å®¹
            cookie_content = "# Netscape HTTP Cookie File\n"
            
            if self.cookies.startswith('SESSDATA='):
                sessdata_value = self.cookies.split('=', 1)[1]
                cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\tSESSDATA\t{sessdata_value}\n"
            elif ';' in self.cookies:
                for cookie in self.cookies.split(';'):
                    cookie = cookie.strip()
                    if '=' in cookie:
                        name, value = cookie.split('=', 1)
                        name = name.strip()
                        value = value.strip()
                        cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\t{name}\t{value}\n"
            else:
                cookie_content += f".bilibili.com\tTRUE\t/\tFALSE\t0\tSESSDATA\t{self.cookies}\n"
            
            with open(self.cookie_file, 'w', encoding='utf-8') as f:
                f.write(cookie_content)
            
            self.logger.info(f"âœ“ Cookieæ–‡ä»¶å·²åˆ›å»º: {self.cookie_file}")
            
        except Exception as e:
            self.logger.error(f"âœ— è®¾ç½®Cookieå¤±è´¥: {e}")
            self.cookie_file = None
    
    def get_yt_dlp_base_args(self):
        """è·å–yt-dlpåŸºç¡€å‚æ•°"""
        args = [
            'yt-dlp',
            '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            '--sleep-interval', '3',
            '--max-sleep-interval', '8',
            '--retries', '5',
            '--fragment-retries', '5',
            '--retry-sleep', '3',
            '--ignore-errors',
            '--no-warnings',
        ]
        
        if self.cookie_file and self.cookie_file.exists():
            args.extend(['--cookies', str(self.cookie_file)])
            self.logger.info(f"âœ“ ä½¿ç”¨Cookieæ–‡ä»¶: {self.cookie_file}")
        
        return args
    
    def get_collection_name(self, collection_url):
        """è·å–åˆé›†åç§°"""
        self.logger.info("æ­£åœ¨è·å–åˆé›†ä¿¡æ¯...")
        
        cmd = self.get_yt_dlp_base_args() + [
            '--dump-json',
            '--no-download',
            '--flat-playlist',
            '--playlist-items', '1',
            collection_url
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if line.strip():
                        try:
                            info = json.loads(line)
                            collection_name = (
                                info.get('playlist_title') or 
                                info.get('uploader', 'Unknown') + '_Collection'
                            )
                            if collection_name and collection_name != 'NA':
                                self.logger.info(f"âœ“ æ‰¾åˆ°åˆé›†åç§°: {collection_name}")
                                return self.sanitize_filename(collection_name)
                        except json.JSONDecodeError:
                            continue
            
            return "Unknown_Collection"
            
        except Exception as e:
            self.logger.warning(f"è·å–åˆé›†ä¿¡æ¯å¤±è´¥: {e}")
            return "Unknown_Collection"
    
    def download_collection(self, collection_url, collection_name=None):
        """ä¸‹è½½æ•´ä¸ªåˆé›†"""
        if not collection_name:
            collection_name = self.get_collection_name(collection_url)
        else:
            collection_name = self.sanitize_filename(collection_name)
        
        self.logger.info(f"å¼€å§‹ä¸‹è½½åˆé›†: {collection_name}")
        self.logger.info(f"URL: {collection_url}")
        
        # åˆ›å»ºåˆé›†ç›®å½•
        collection_dir = self.output_dir / collection_name
        collection_dir.mkdir(exist_ok=True)
        self.logger.info(f"åˆé›†ç›®å½•: {collection_dir}")
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨æ ¼å¼å›é€€ä¸‹è½½ï¼ˆæ¢å¤ä¹‹å‰æˆåŠŸçš„é€»è¾‘ï¼‰
        success = self.download_with_format_fallback(collection_url, collection_dir)
        
        if success:
            # ç¬¬äºŒæ­¥ï¼šé‡å‘½åæ–‡ä»¶ï¼ˆä¿®å¤åçš„é€»è¾‘ï¼‰
            self.logger.info("=" * 50)
            self.logger.info("å¼€å§‹é‡å‘½åé˜¶æ®µ...")
            self.logger.info("=" * 50)
            self.rename_files_correctly(collection_dir, collection_name)
        
        return success
    
    def download_with_format_fallback(self, collection_url, collection_dir):
        """ä½¿ç”¨æ ¼å¼å›é€€ä¸‹è½½ï¼ˆæ¢å¤ä¹‹å‰æˆåŠŸçš„é€»è¾‘ï¼‰"""
        self.logger.info("å¼€å§‹ä¸‹è½½åˆé›†ï¼ˆä½¿ç”¨æ ¼å¼å›é€€ï¼‰...")
        
        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç‰¹å®šæ ¼å¼ï¼Œå…ˆå°è¯•ç”¨æˆ·æ ¼å¼
        formats_to_try = []
        if self.quality not in self.format_fallbacks:
            formats_to_try.append(self.quality)
        formats_to_try.extend(self.format_fallbacks)
        
        for format_selector in formats_to_try:
            self.logger.info(f"å°è¯•æ ¼å¼: {format_selector}")
            
            if self.download_with_format(collection_url, collection_dir, format_selector):
                self.logger.info(f"âœ“ ä½¿ç”¨æ ¼å¼ {format_selector} ä¸‹è½½æˆåŠŸ")
                return True
            else:
                self.logger.warning(f"æ ¼å¼ {format_selector} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
        
        self.logger.error(f"âœ— æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥")
        return False
    
    def download_with_format(self, collection_url, collection_dir, format_selector):
        """ä½¿ç”¨æŒ‡å®šæ ¼å¼ä¸‹è½½"""
        try:
            cmd = self.get_yt_dlp_base_args() + [
                '--format', format_selector,
                '--output', '%(playlist_index)02d_%(id)s.%(ext)s',  # ä½¿ç”¨åºå·_IDçš„å‘½åæ–¹å¼
                '--write-info-json',
                '--write-thumbnail',
                '--convert-thumbnails', 'jpg',
                collection_url
            ]
            
            # é™åˆ¶ä¸‹è½½æ•°é‡
            if self.max_videos:
                cmd.extend(['--playlist-end', str(self.max_videos)])
            
            self.logger.info(f"æ‰§è¡Œä¸‹è½½å‘½ä»¤...")
            
            result = subprocess.run(
                cmd, 
                cwd=collection_dir, 
                capture_output=True, 
                text=True,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            if result.returncode == 0:
                self.logger.info(f"âœ“ ä¸‹è½½å®Œæˆ")
                
                # æ˜¾ç¤ºä¸‹è½½çš„æ–‡ä»¶
                downloaded_files = list(collection_dir.glob('*'))
                self.logger.info(f"ä¸‹è½½äº† {len(downloaded_files)} ä¸ªæ–‡ä»¶")
                
                return True
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¼å¼é—®é¢˜
                if "Requested format is not available" in result.stderr:
                    self.logger.warning(f"æ ¼å¼ä¸å¯ç”¨: {format_selector}")
                    return False  # æ ¼å¼ä¸å¯ç”¨ï¼Œä¸é‡è¯•
                else:
                    self.logger.warning(f"ä¸‹è½½å¤±è´¥: {result.stderr}")
                    return False
                
        except subprocess.TimeoutExpired:
            self.logger.warning(f"ä¸‹è½½è¶…æ—¶")
            return False
        except Exception as e:
            self.logger.warning(f"ä¸‹è½½å‡ºé”™: {e}")
            return False
    
    def rename_files_correctly(self, collection_dir, collection_name):
        """æ­£ç¡®é‡å‘½åæ–‡ä»¶ - ä¿®å¤åçš„é€»è¾‘"""
        self.logger.info("å¼€å§‹é‡å‘½åæ–‡ä»¶ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰...")
        
        # æŸ¥æ‰¾æ‰€æœ‰info.jsonæ–‡ä»¶
        info_files = list(collection_dir.glob('*.info.json'))
        self.logger.info(f"æ‰¾åˆ° {len(info_files)} ä¸ªinfo.jsonæ–‡ä»¶")
        
        if not info_files:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°info.jsonæ–‡ä»¶")
            return
        
        renamed_count = 0
        
        for info_file in info_files:
            self.logger.info(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {info_file.name}")
            
            try:
                # è¯»å–å¹¶è§£æinfo.json
                with open(info_file, 'r', encoding='utf-8') as f:
                    video_info = json.load(f)
                
                # è·å–æ ‡é¢˜ - å…³é”®ä¿®å¤ç‚¹
                title = video_info.get('title')
                if not title:
                    title = video_info.get('fulltitle')
                if not title:
                    title = video_info.get('display_id')
                
                if not title:
                    self.logger.warning(f"  âš ï¸ æ— æ³•è·å–æ ‡é¢˜ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                    continue
                
                self.logger.info(f"  ğŸ“º åŸå§‹æ ‡é¢˜: '{title}'")
                
                # æ¸…ç†æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å
                safe_title = self.sanitize_filename(title)
                self.logger.info(f"  ğŸ“ æ¸…ç†åæ–‡ä»¶å: '{safe_title}'")
                
                if not safe_title or safe_title == 'untitled':
                    self.logger.warning(f"  âš ï¸ æ–‡ä»¶åæ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡")
                    continue
                
                # è·å–åŸå§‹æ–‡ä»¶å‰ç¼€
                original_prefix = info_file.stem  # å»æ‰.info.jsonåç¼€
                self.logger.info(f"  ğŸ”¤ åŸå§‹å‰ç¼€: '{original_prefix}'")
                
                # æ‰§è¡Œé‡å‘½å
                success = self.rename_file_group(collection_dir, original_prefix, safe_title)
                
                if success:
                    # ç”Ÿæˆnfoæ–‡ä»¶
                    self.generate_nfo(video_info, collection_dir, safe_title, collection_name)
                    renamed_count += 1
                
            except Exception as e:
                self.logger.error(f"  âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
                import traceback
                self.logger.error(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        self.logger.info(f"\nğŸ‰ é‡å‘½åå®Œæˆ: {renamed_count}/{len(info_files)} ä¸ªæ–‡ä»¶ç»„")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        self.show_final_results(collection_dir)
    
    def rename_file_group(self, collection_dir, original_prefix, new_name):
        """é‡å‘½åä¸€ç»„ç›¸å…³æ–‡ä»¶"""
        # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        pattern = f'{original_prefix}.*'
        related_files = list(collection_dir.glob(pattern))
        
        self.logger.info(f"  ğŸ“‚ æŸ¥æ‰¾æ¨¡å¼: '{pattern}'")
        self.logger.info(f"  ğŸ“‚ æ‰¾åˆ°ç›¸å…³æ–‡ä»¶: {len(related_files)}ä¸ª")
        
        if not related_files:
            self.logger.warning(f"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡ä»¶")
            return False
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶
        for file in related_files:
            self.logger.info(f"    - {file.name}")
        
        success_count = 0
        
        for file in related_files:
            try:
                # ç¡®å®šæ–°æ–‡ä»¶å
                if file.suffix == '.json' and 'info' in file.name:
                    new_filename = f'{new_name}.info.json'
                elif file.suffix.lower() in ['.mp4', '.flv', '.mkv', '.webm']:
                    new_filename = f'{new_name}{file.suffix}'
                elif file.suffix.lower() in ['.jpg', '.png', '.webp']:
                    new_filename = f'{new_name}{file.suffix}'
                else:
                    new_filename = f'{new_name}{file.suffix}'
                
                new_path = collection_dir / new_filename
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
                if file.name == new_filename:
                    self.logger.info(f"    âœ“ æ–‡ä»¶åå·²æ­£ç¡®: {file.name}")
                    success_count += 1
                    continue
                
                # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if new_path.exists():
                    self.logger.warning(f"    âš ï¸ ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨: {new_filename}")
                    continue
                
                # æ‰§è¡Œé‡å‘½å
                self.logger.info(f"    ğŸ”„ é‡å‘½å: {file.name} -> {new_filename}")
                file.rename(new_path)
                self.logger.info(f"    âœ… é‡å‘½åæˆåŠŸ")
                success_count += 1
                
            except Exception as e:
                self.logger.error(f"    âŒ é‡å‘½åå¤±è´¥ {file.name}: {e}")
        
        return success_count > 0
    
    def show_final_results(self, collection_dir):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        final_files = list(collection_dir.glob('*'))
        self.logger.info(f"\nğŸ“ æœ€ç»ˆæ–‡ä»¶åˆ—è¡¨ ({len(final_files)}ä¸ª):")
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        video_files = [f for f in final_files if f.suffix.lower() in ['.mp4', '.flv', '.mkv', '.webm']]
        nfo_files = [f for f in final_files if f.suffix == '.nfo']
        info_files = [f for f in final_files if f.suffix == '.json' and 'info' in f.name]
        
        self.logger.info(f"  ğŸ¬ è§†é¢‘æ–‡ä»¶ ({len(video_files)}ä¸ª):")
        for file in sorted(video_files):
            self.logger.info(f"    - {file.name}")
        
        if nfo_files:
            self.logger.info(f"  ğŸ“„ NFOæ–‡ä»¶ ({len(nfo_files)}ä¸ª):")
            for file in sorted(nfo_files):
                self.logger.info(f"    - {file.name}")
        
        if info_files:
            self.logger.info(f"  ğŸ“‹ Infoæ–‡ä»¶ ({len(info_files)}ä¸ª):")
            for file in sorted(info_files):
                self.logger.info(f"    - {file.name}")
    
    def generate_nfo(self, video_info, output_dir, filename, collection_name):
        """ç”Ÿæˆnfoæ–‡ä»¶"""
        try:
            nfo_path = output_dir / f'{filename}.nfo'
            
            if nfo_path.exists():
                self.logger.info(f"    âœ“ NFOæ–‡ä»¶å·²å­˜åœ¨: {filename}.nfo")
                return
            
            # åˆ›å»ºç®€å•çš„nfoå†…å®¹
            nfo_content = f"""<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<movie>
    <title>{video_info.get('title', 'Unknown')}</title>
    <originaltitle>{video_info.get('title', 'Unknown')}</originaltitle>
    <plot>{video_info.get('description', '')[:500]}</plot>
    <director>{video_info.get('uploader', '')}</director>
    <runtime>{int(video_info.get('duration', 0) / 60) if video_info.get('duration') else 0}</runtime>
    <premiered>{video_info.get('upload_date', '')[:4]}-{video_info.get('upload_date', '')[4:6]}-{video_info.get('upload_date', '')[6:8] if len(video_info.get('upload_date', '')) >= 8 else ''}</premiered>
    <tag>{collection_name}</tag>
    <tag>Bilibili</tag>
    <uniqueid type="bilibili">{video_info.get('id', '')}</uniqueid>
    <website>{video_info.get('webpage_url', '')}</website>
</movie>"""
            
            with open(nfo_path, 'w', encoding='utf-8') as f:
                f.write(nfo_content)
            
            self.logger.info(f"    âœ“ NFOæ–‡ä»¶ç”Ÿæˆ: {filename}.nfo")
            
        except Exception as e:
            self.logger.error(f"    âœ— NFOç”Ÿæˆå¤±è´¥: {e}")
    
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        if not filename or filename.strip() == '':
            return 'untitled'
        
        # ç§»é™¤éæ³•å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'[\r\n\t]', ' ', filename)
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = filename.strip('. ')
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™ä¸­æ–‡
        filename = re.sub(r'[ã€ã€‘\[\]()ï¼ˆï¼‰]', '', filename)
        filename = re.sub(r'[!ï¼@#$%^&*+={}|;:,.<>?~`]', '_', filename)
        
        # é™åˆ¶é•¿åº¦
        if len(filename) > 80:
            filename = filename[:80].rsplit(' ', 1)[0]
        
        return filename or 'untitled'
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self.cookie_file and self.cookie_file.name == 'cookies.txt':
            try:
                if self.cookie_file.exists():
                    self.cookie_file.unlink()
            except:
                pass

def main():
    parser = argparse.ArgumentParser(description='Bç«™åˆé›†ä¸‹è½½å™¨ - åŸºäºæˆåŠŸç‰ˆæœ¬ä¿®å¤é‡å‘½å')
    parser.add_argument('url', help='Bç«™åˆé›†URL')
    parser.add_argument('output', help='è¾“å‡ºæ ¹ç›®å½•')
    parser.add_argument('--name', help='è‡ªå®šä¹‰åˆé›†åç§°')
    parser.add_argument('--max-videos', type=int, help='æœ€å¤§ä¸‹è½½è§†é¢‘æ•°é‡')
    parser.add_argument('--quality', default='best', help='è§†é¢‘è´¨é‡')
    parser.add_argument('--cookies', help='Cookieå­—ç¬¦ä¸²æˆ–Cookieæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    if 'bilibili.com' not in args.url or 'lists' not in args.url:
        print("é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„Bç«™åˆé›†URL")
        sys.exit(1)
    
    downloader = BilibiliWorkingDownloader(
        output_dir=args.output,
        max_videos=args.max_videos,
        quality=args.quality,
        cookies=args.cookies
    )
    
    if args.verbose:
        logging.getLogger().setLevel(logging.INFO)
    
    print(f"ğŸš€ Bç«™åˆé›†ä¸‹è½½å™¨ - ä¿®å¤ç‰ˆæœ¬")
    print(f"  è¾“å‡ºç›®å½•: {args.output}")
    print(f"  æœ€å¤§è§†é¢‘æ•°: {args.max_videos or 'æ— é™åˆ¶'}")
    print(f"  è§†é¢‘è´¨é‡: {args.quality}")
    print(f"  Cookie: {'âœ“' if args.cookies else 'âœ—'}")
    print(f"  ç­–ç•¥: æ ¼å¼å›é€€ + ä¿®å¤é‡å‘½å")
    print()
    
    try:
        success = downloader.download_collection(args.url, args.name)
        if success:
            print(f"\nâœ… ä¸‹è½½å’Œé‡å‘½åå®Œæˆ!")
            print(f"ğŸ“ æ–‡ä»¶å·²ä½¿ç”¨è§†é¢‘çœŸå®æ ‡é¢˜å‘½å")
        else:
            print(f"\nâŒ ä¸‹è½½å¤±è´¥!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        sys.exit(1)
    finally:
        downloader.cleanup()

if __name__ == '__main__':
    main()

